{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "\n",
    "from os.path import expanduser\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up reader\n",
    "# NB: If you do not have the CLTK-Tesserae corpus already installed in CLTK_DATA, you will be prompted to download the corpus.\n",
    "\n",
    "T = LatinTesseraeCorpusReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fileids and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First 10 filesnames\n",
    "\n",
    "files = T.fileids()[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. author\n",
    "files = T.fileids(author='horace')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. mode\n",
    "files = T.fileids(mode='verse')[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. date\n",
    "files = T.fileids(date=54)\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. date & mode\n",
    "files = T.fileids(date=54, mode='verse')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. max_date\n",
    "\n",
    "files = T.fileids(max_date=150)[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files by metadata; e.g. filename match\n",
    "\n",
    "files = T.fileids(match='lucretius')[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for file\n",
    "\n",
    "file = T.fileids()[0]\n",
    "\n",
    "print(file)\n",
    "print(T.metadata('mode', file))\n",
    "pprint(T._metadata[file]) # TODO: should make this more direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catullus = 'catullus.carmina.tess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Docs\n",
    "\n",
    "catullus_docs = T.docs(catullus)\n",
    "catullus_doc = next(catullus_docs)\n",
    "print(catullus_doc[:446])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Texts\n",
    "\n",
    "catullus_texts = T.texts(catullus)\n",
    "catullus_text = next(catullus_texts)\n",
    "pprint(catullus_text[:335])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doc Rows\n",
    "\n",
    "catullus_docrows = T.doc_rows(catullus)\n",
    "\n",
    "print('This is a string representation of what the output dictionary looks like...')\n",
    "print(f'{str(next(catullus_docrows))[:94]} etc. }}\\n')\n",
    "\n",
    "\n",
    "catullus_docrows = T.doc_rows(catullus)\n",
    "print('Here are the first 10 items of the dict output...')\n",
    "pprint(list(next(catullus_docrows).items())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catilinam = 'cicero.in_catilinam.tess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paras (not implemented)\n",
    "\n",
    "# catilinam_paras = T.paras(catilinam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sents\n",
    "\n",
    "# By default, segmentation, tokenization, and other tagging is done using the spaCy model 'la_core_web_lg'\n",
    "\n",
    "catilinam_sents = T.sents(catilinam)\n",
    "\n",
    "for i in range(1,6):\n",
    "    print(f'Sent {i}: {next(catilinam_sents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words\n",
    "\n",
    "catilinam_words = T.tokens(catilinam)\n",
    "\n",
    "for i in range(1,10):\n",
    "    print(f'Word {i}: {next(catilinam_words)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([item for item in dir(type(next(catilinam_words))) if not item.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = t = next(catilinam_words)\n",
    "print(t.text, t.lemma_, t.pos_, t.tag_, t.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass a preprocessor to `words` (or `sents`, etc.)\n",
    "\n",
    "def custom_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',','').replace('?','')\n",
    "    return text\n",
    "\n",
    "catilinam_words = T.tokens(catilinam, preprocess=custom_preprocess)\n",
    "\n",
    "for i in range(1,8):\n",
    "    print(f'Word {i}: {next(catilinam_words)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized sents\n",
    "\n",
    "# i.e. Sents in the form of a list of tuples of the form `(token, lemma, tag)`\n",
    "\n",
    "catilinam_tokenized_sents = T.tokenized_sents(catilinam)\n",
    "\n",
    "for i in range(1,4):\n",
    "    print(f'Tok Sent {i}: {next(catilinam_tokenized_sents)}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized sents, simplified\n",
    "\n",
    "# i.e. Sents in the form of a list of tokens\n",
    "\n",
    "catilinam_tokenized_sents = T.tokenized_sents(catilinam, simple=True)\n",
    "\n",
    "for i in range(1,4):\n",
    "    print(f'Tok Sent {i}: {next(catilinam_tokenized_sents)}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS-tagged sents\n",
    "\n",
    "# i.e. Sents in the form of a list of strings of the form `token/POS`\n",
    "\n",
    "catilinam_pos_sents = T.pos_sents(catilinam)\n",
    "\n",
    "for i in range(1,2):\n",
    "    print(f'POS Sent {i}: {next(catilinam_pos_sents)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note spacy objects are output by default\n",
    "print(type(next(catilinam_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens, with plaintext output\n",
    "\n",
    "plaintext_tokens = T.tokens(catilinam, plaintext=True)\n",
    "\n",
    "plaintext_token = next(plaintext_tokens)\n",
    "print(plaintext_token)\n",
    "print(type(plaintext_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines (designed for verse)\n",
    "\n",
    "aeneid = T.fileids(match='aeneid')[0]\n",
    "\n",
    "aeneid_lines = T.lines(aeneid)\n",
    "\n",
    "for i in range(1,9):\n",
    "    print(f'{i}: {next(aeneid_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines, maintaining citation information\n",
    "\n",
    "aeneid_lines = T.lines(aeneid)\n",
    "\n",
    "for i in range(1,9):\n",
    "    line = next(aeneid_lines)\n",
    "    print(f'{line._.citation}: {line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences, maintaing citation information, inc. over line breaks; also maintain metadata\n",
    "\n",
    "aeneid_sents = T.sents(aeneid)\n",
    "aeneid_sent = next(aeneid_sents)\n",
    "\n",
    "print(aeneid_sent.text)\n",
    "print(aeneid_sent._.sentence_citation)\n",
    "print(aeneid_sent._.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens, maintaing citation information, inc. over line breaks; also maintain metadata\n",
    "\n",
    "aeneid_words = T.tokens(aeneid)\n",
    "aeneid_word = next(aeneid_words)\n",
    "\n",
    "print(aeneid_word.text)\n",
    "print(aeneid_word._.citation)\n",
    "print(aeneid_word._.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorphoses = T.fileids(author='ovid', match='metamorphoses') # TODO: Add titles to metadata\n",
    "pprint(metamorphoses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocess(text):\n",
    "    from cltk.alphabet.lat import JVReplacer\n",
    "    replacer = JVReplacer()\n",
    "\n",
    "    text = text.lower() # Lowercase\n",
    "    text = replacer.replace(text)  # Normalize u/v & i/j\n",
    "\n",
    "    # Remove punctuation\n",
    "    punctuation =\"\\\"#$%&\\'()*+,/:;<=>@[\\]^_`{|}~.?!«»—“-”\"\n",
    "    misc = '¡£¤¥¦§¨©¯°±²³´µ¶·¸¹º¼½¾¿÷·–‘’†•ↄ∞⏑〈〉（）'\n",
    "    misc += punctuation\n",
    "    translator = str.maketrans({key: \" \" for key in misc})\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # Remove numbers\n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    return \" \".join(text.split()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concordance, using Tesserae citations\n",
    "# Not working\n",
    "\n",
    "# metamorphoses_concordances = T.concordance(metamorphoses, preprocess=custom_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Basic descriptive data; note takes several minutes to run\n",
    "\n",
    "# tess_describe = T.describe()\n",
    "# pprint(tess_describe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output:  \n",
    "\n",
    "{'files': 748,  \n",
    " 'lexdiv': 24.255701516259066,  \n",
    " 'secs': 143.71532320976257,  \n",
    " 'sents': 314436,  \n",
    " 'vocab': 329693,  \n",
    " 'words': 7996935}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This data can also be returned for individual files or lists of files\n",
    "\n",
    "print('Stats on just the file \\'catullus.carmina.tess\\'')\n",
    "pprint(T.describe(catullus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cltk-readers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "005fec92dbb77c913c093232e88e8270231540d56d0752cd93eef03799bca324"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
